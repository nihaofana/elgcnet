{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IZ2J-xLcDF5"
      },
      "source": [
        "# ELGC-Net 快速训练 (GitHub集成版)\n",
        "\n",
        "这个Notebook直接使用GitHub中的配置文件，无需手动创建任何文件。\n",
        "\n",
        "## 步骤概览\n",
        "1. 挂载Google Drive\n",
        "2. 克隆项目\n",
        "3. 安装依赖\n",
        "4. 准备数据集\n",
        "5. 开始训练\n",
        "6. 评估模型（可选）\n",
        "7. 保存结果（可选）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lFOJmHGcDF7",
        "outputId": "17eb54bc-d947-42d4-efb4-f04c73d745e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Fri Jun  6 08:48:06 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# 1. 挂载Google Drive并设置环境\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
        "\n",
        "# 检查GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4Zb6OCbcDF8",
        "outputId": "45110328-8536-4f86-d2f0-1f5dd5cd89a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'elgcnet'...\n",
            "remote: Enumerating objects: 153, done.\u001b[K\n",
            "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 153 (delta 46), reused 53 (delta 24), pack-reused 73 (from 2)\u001b[K\n",
            "Receiving objects: 100% (153/153), 2.10 MiB | 30.25 MiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n",
            "/content/elgcnet\n",
            "total 56\n",
            "drwxr-xr-x 2 root root 4096 Jun  6 08:48 .\n",
            "drwxr-xr-x 8 root root 4096 Jun  6 08:48 ..\n",
            "-rw-r--r-- 1 root root  560 Jun  6 08:48 colab_config.py\n",
            "-rw-r--r-- 1 root root 4694 Jun  6 08:48 correct_notebook.ipynb\n",
            "-rw-r--r-- 1 root root 2311 Jun  6 08:48 eval_colab.py\n",
            "-rw-r--r-- 1 root root 2122 Jun  6 08:48 monitor_training.py\n",
            "-rw-r--r-- 1 root root 6096 Jun  6 08:48 prepare_data_balanced.py\n",
            "-rw-r--r-- 1 root root 3046 Jun  6 08:48 prepare_data.py\n",
            "-rw-r--r-- 1 root root 1650 Jun  6 08:48 README.md\n",
            "-rw-r--r-- 1 root root 1911 Jun  6 08:48 save_results.py\n",
            "-rw-r--r-- 1 root root 2755 Jun  6 08:48 train_colab.py\n",
            "-rw-r--r-- 1 root root 3943 Jun  6 08:48 train_colab_weighted.py\n"
          ]
        }
      ],
      "source": [
        "# 2. 克隆项目（包含colab文件夹）\n",
        "!rm -rf /content/elgcnet  # 清理旧文件\n",
        "!git clone https://github.com/nihaofana/elgcnet.git\n",
        "%cd /content/elgcnet\n",
        "\n",
        "# 查看colab目录\n",
        "!ls -la colab/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vbhWcHZcDF9",
        "outputId": "8aced0f7-78f2-4351-a4bb-2f1dd1811987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m41.0/50.2 kB\u001b[0m \u001b[31m154.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m600.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "PyTorch: 2.6.0+cu124\n",
            "CUDA可用: True\n"
          ]
        }
      ],
      "source": [
        "# 3. 安装依赖\n",
        "!pip install einops==0.3.2 timm==0.9.16 fvcore opencv-python scikit-learn tqdm -q\n",
        "\n",
        "import torch\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA可用: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "57gkEMiCcDF9"
      },
      "outputs": [],
      "source": [
        "# 4. 准备数据集（仅复制部分数据以加快训练）\n",
        "# !python colab/prepare_data.py --train_samples 100 --val_samples 25 --test_samples 25"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 删除之前下载的数据集\n",
        "# !rm -rf ./datasets/CD/LEVIR-CD-256\n",
        "\n",
        "# # 确认删除完成\n",
        "# !ls -la ./datasets/CD/"
      ],
      "metadata": {
        "id": "nDrCXdM06gIF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用改进脚本，大幅增加数据量\n",
        "!python colab/prepare_data_balanced.py --train_samples 1000 --val_samples 200 --test_samples 200"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6L2130a6t9D",
        "outputId": "f0a5e4c3-f2a8-4e24-be9c-b9fb9697c482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "开始智能选择数据集样本...\n",
            "\n",
            "分析 train 集...\n",
            "  分析进度: 0/7120\n",
            "  分析进度: 100/7120\n",
            "  分析进度: 200/7120\n",
            "  分析进度: 300/7120\n",
            "  分析进度: 400/7120\n",
            "  分析进度: 500/7120\n",
            "  分析进度: 600/7120\n",
            "  分析进度: 700/7120\n",
            "  分析进度: 800/7120\n",
            "  分析进度: 900/7120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sREw5XJQcDF9"
      },
      "outputs": [],
      "source": [
        "# 5. 开始训练\n",
        "!rm -rf ./checkpoints/elgcnet_levir_colab\n",
        "!python colab/train_colab.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQtIi5ojcDF-"
      },
      "source": [
        "## 可选操作"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It6M7hlHcDF-"
      },
      "outputs": [],
      "source": [
        "# 6. 评估模型（可选）\n",
        "!python colab/eval_colab.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python analyze_dataset.py"
      ],
      "metadata": {
        "id": "TqxnEc2suAKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 直接使用加权损失重新训练，不需要重新准备数据\n",
        "!python colab/train_colab_weighted.py"
      ],
      "metadata": {
        "id": "a-_We9Dkxg7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建上面的 eval_weighted.py 文件，然后运行\n",
        "!python eval_weighted.py"
      ],
      "metadata": {
        "id": "pRtsIFFq0ijw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 先检查数组的实际结构\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    # 加载数据\n",
        "    weighted_train = np.load('./checkpoints/elgcnet_levir_colab_weighted/train_acc.npy')\n",
        "    weighted_val = np.load('./checkpoints/elgcnet_levir_colab_weighted/val_acc.npy')\n",
        "\n",
        "    print(\"📊 数据结构分析:\")\n",
        "    print(f\"训练数据形状: {weighted_train.shape}\")\n",
        "    print(f\"验证数据形状: {weighted_val.shape}\")\n",
        "    print(f\"训练数据类型: {type(weighted_train)}\")\n",
        "    print(f\"验证数据类型: {type(weighted_val)}\")\n",
        "\n",
        "    print(f\"\\n训练数据内容:\")\n",
        "    print(weighted_train)\n",
        "\n",
        "    print(f\"\\n验证数据内容:\")\n",
        "    print(weighted_val)\n",
        "\n",
        "    # 如果是1D数组，可能只保存了最佳分数\n",
        "    if weighted_train.ndim == 1:\n",
        "        print(f\"\\n⚠️ 注意: 数据是1D格式\")\n",
        "        print(f\"训练数据长度: {len(weighted_train)}\")\n",
        "        print(f\"验证数据长度: {len(weighted_val)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ 无法加载数据: {e}\")"
      ],
      "metadata": {
        "id": "OzBh2KdX3Mce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 修复版：正确处理训练历史数据\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def analyze_weighted_training_history():\n",
        "    \"\"\"正确分析加权训练历史\"\"\"\n",
        "\n",
        "    checkpoint_dir = './checkpoints/elgcnet_levir_colab_weighted'\n",
        "\n",
        "    try:\n",
        "        # 检查并加载训练历史\n",
        "        train_file = os.path.join(checkpoint_dir, 'train_acc.npy')\n",
        "        val_file = os.path.join(checkpoint_dir, 'val_acc.npy')\n",
        "\n",
        "        if os.path.exists(train_file) and os.path.exists(val_file):\n",
        "            weighted_train = np.load(train_file)\n",
        "            weighted_val = np.load(val_file)\n",
        "\n",
        "            print(\"📊 加权训练历史分析:\")\n",
        "            print(f\"训练数据形状: {weighted_train.shape}\")\n",
        "            print(f\"验证数据形状: {weighted_val.shape}\")\n",
        "\n",
        "            # 根据实际格式处理数据\n",
        "            if weighted_train.ndim == 1:\n",
        "                # 1D格式 - 可能每个元素代表一个epoch的分数\n",
        "                print(f\"训练轮数: {len(weighted_train)}\")\n",
        "                print(f\"训练分数变化: {weighted_train}\")\n",
        "                print(f\"验证分数变化: {weighted_val}\")\n",
        "                print(f\"最佳训练分数: {np.max(weighted_train):.4f}\")\n",
        "                print(f\"最佳验证分数: {np.max(weighted_val):.4f}\")\n",
        "                print(f\"最终训练分数: {weighted_train[-1]:.4f}\")\n",
        "                print(f\"最终验证分数: {weighted_val[-1]:.4f}\")\n",
        "\n",
        "                # 绘制1D数据\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                epochs = range(len(weighted_train))\n",
        "                plt.plot(epochs, weighted_train, 'b-o', label='Train Score', linewidth=2)\n",
        "                plt.plot(epochs, weighted_val, 'r-o', label='Val Score', linewidth=2)\n",
        "                plt.title('加权训练历史')\n",
        "                plt.xlabel('Epoch')\n",
        "                plt.ylabel('Score')\n",
        "                plt.legend()\n",
        "                plt.grid(True, alpha=0.3)\n",
        "                plt.show()\n",
        "\n",
        "            elif weighted_train.ndim == 2:\n",
        "                # 2D格式 - 每行包含多个指标\n",
        "                print(f\"训练轮数: {weighted_train.shape[0]}\")\n",
        "                print(f\"指标数量: {weighted_train.shape[1]}\")\n",
        "\n",
        "                # 假设列顺序是 [acc, miou, mf1, ...]\n",
        "                if weighted_train.shape[1] >= 3:\n",
        "                    print(f\"最佳训练mF1: {np.max(weighted_train[:, 2]):.4f}\")\n",
        "                    print(f\"最佳验证mF1: {np.max(weighted_val[:, 2]):.4f}\")\n",
        "                    print(f\"最终训练mF1: {weighted_train[-1, 2]:.4f}\")\n",
        "                    print(f\"最终验证mF1: {weighted_val[-1, 2]:.4f}\")\n",
        "\n",
        "                    # 绘制2D数据\n",
        "                    plt.figure(figsize=(15, 5))\n",
        "\n",
        "                    plt.subplot(1, 3, 1)\n",
        "                    plt.plot(weighted_train[:, 0], 'b-', label='Train Acc')\n",
        "                    plt.plot(weighted_val[:, 0], 'r-', label='Val Acc')\n",
        "                    plt.title('Accuracy')\n",
        "                    plt.legend()\n",
        "                    plt.grid(True)\n",
        "\n",
        "                    plt.subplot(1, 3, 2)\n",
        "                    plt.plot(weighted_train[:, 1], 'b-', label='Train mIoU')\n",
        "                    plt.plot(weighted_val[:, 1], 'r-', label='Val mIoU')\n",
        "                    plt.title('mIoU')\n",
        "                    plt.legend()\n",
        "                    plt.grid(True)\n",
        "\n",
        "                    plt.subplot(1, 3, 3)\n",
        "                    plt.plot(weighted_train[:, 2], 'b-', label='Train mF1')\n",
        "                    plt.plot(weighted_val[:, 2], 'r-', label='Val mF1')\n",
        "                    plt.title('mF1')\n",
        "                    plt.legend()\n",
        "                    plt.grid(True)\n",
        "\n",
        "                    plt.tight_layout()\n",
        "                    plt.show()\n",
        "\n",
        "        else:\n",
        "            print(\"❌ 训练历史文件不存在\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 分析训练历史时出错: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# 同时检查日志文件\n",
        "def check_training_log():\n",
        "    \"\"\"检查训练日志文件\"\"\"\n",
        "    log_file = './checkpoints/elgcnet_levir_colab_weighted/log.txt'\n",
        "\n",
        "    if os.path.exists(log_file):\n",
        "        print(\"\\n📄 训练日志分析:\")\n",
        "        with open(log_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        # 查找关键信息\n",
        "        best_epochs = []\n",
        "        final_metrics = []\n",
        "\n",
        "        for line in lines:\n",
        "            if \"Best model updated\" in line:\n",
        "                best_epochs.append(line.strip())\n",
        "            if \"epoch_mF1=\" in line and \"Is_training: False\" in line:\n",
        "                final_metrics.append(line.strip())\n",
        "\n",
        "        print(f\"最佳模型更新次数: {len(best_epochs)}\")\n",
        "        if best_epochs:\n",
        "            print(\"最佳模型更新记录:\")\n",
        "            for update in best_epochs[-3:]:  # 显示最后3次更新\n",
        "                print(f\"  {update}\")\n",
        "\n",
        "        if final_metrics:\n",
        "            print(f\"\\n最后几次验证结果:\")\n",
        "            for metric in final_metrics[-3:]:  # 显示最后3次验证\n",
        "                print(f\"  {metric}\")\n",
        "    else:\n",
        "        print(\"❌ 日志文件不存在\")\n",
        "\n",
        "# 运行分析\n",
        "analyze_weighted_training_history()\n",
        "check_training_log()"
      ],
      "metadata": {
        "id": "KZbSOtNc4ZuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gV8Ad3QFcDF-"
      },
      "outputs": [],
      "source": [
        "# 7. 保存结果到Drive（可选）\n",
        "!python colab/save_results.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0lql1OOcDF-"
      },
      "outputs": [],
      "source": [
        "# 8. 监控GPU使用（可选）\n",
        "# 在训练过程中，在新的cell中运行此代码\n",
        "import sys\n",
        "sys.path.append('/content/elgcnet/colab')\n",
        "from monitor_training import monitor_gpu\n",
        "\n",
        "# 监控60秒\n",
        "monitor_gpu(duration=60, interval=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b2cZL44cDF_"
      },
      "source": [
        "## 配置说明\n",
        "\n",
        "### 修改训练参数\n",
        "如需修改训练参数，编辑 `colab/colab_config.py`：\n",
        "\n",
        "```python\n",
        "class ColabConfig:\n",
        "    BATCH_SIZE = 8      # 批次大小\n",
        "    MAX_EPOCHS = 100    # 训练轮数\n",
        "    LEARNING_RATE = 0.00031  # 学习率\n",
        "```\n",
        "\n",
        "### 数据集路径\n",
        "确保数据集在Google Drive的以下位置：\n",
        "```\n",
        "/content/drive/My Drive/Change_Detection/LEVIR-CD-256/\n",
        "```\n",
        "\n",
        "### 故障排除\n",
        "1. **GPU内存不足**：减小BATCH_SIZE\n",
        "2. **找不到数据集**：检查Google Drive路径\n",
        "3. **训练中断**：模型会自动保存，可以从检查点恢复"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}